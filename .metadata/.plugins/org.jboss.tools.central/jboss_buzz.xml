<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">Testing spring-boot KIE server images built with Jib and Buildpacks</title><link rel="alternate" href="https://blog.kie.org/2022/08/testing-spring-boot-kie-server-images.html" /><author><name>Gonzalo Muñoz Fernández</name></author><id>https://blog.kie.org/2022/08/testing-spring-boot-kie-server-images.html</id><updated>2022-08-05T12:16:59Z</updated><content type="html">“The purpose of devtools is to improve developers’ lives” (Ixchel Ruiz) MOTIVATION: BUILD AND TEST IMAGES IN THE SAME PROCESS Following the previous article about “”, now we are going through modern Cloud Native tools for building the images (Jib and Buildpacks) and testing them using maven plugins and testcontainers library. These Image Builders are an alternative to Dockerfiles and provide standardization out-of-the-box for continuous image creation. They are easy to maintain and allow some parameterization. They also can take advantage of layering (as we talked about in the previous article) to split up among different layers from top to bottom: * Business applications (kjars) * Resources * Application classes * KIE server libraries * spring-boot libraries * JRE * OS Layering has the benefit, for example, of allowing patches of lower layers in the event of security upgrades without compromising the application’s integrity and operation. The main goal of this article is to showof how we can build these images with both tools and test them, into the maven lifecycle. Both of these tools are interchangeable and they can even coexist in the same pom. We will accomplish this by using two different profiles in our pom: jib and buildpack. TESTING INFRASTRUCTURE The SpringbootKieContainer (that we will use in our tests) class inherits from testcontainers GenericContainer class and it’s generated during the testing phase (maven-surefire-plugin).  Inspired by the (thanks Sergei!) of having a Future that resolves the name of the spring-boot application to be built (a.k.a. system-under-test), we will create this container from it: public SpringbootKieContainer() { super(IMAGE_FUTURE) withExposedPorts(KIE_PORT); withLogConsumer(...); withNetwork(Network.SHARED); withEnv("SPRING_DATASOURCE_URL", "jdbc:postgresql://db:5432/…"); withEnv("JAVA_TOOL_OPTIONS", "-Dorg.kie.maven.resolver.folder=..."); waitingFor(Wait.forLogMessage(".*Started KieServerApplication in.*", 1).withStartupTimeout(Duration.ofMinutes(5L))); } We override the resolve method of the testcontainers LazyFuture class executing the package phase with the corresponding goal for each builder: * The profile “jib” has as goal property “jib:dockerBuild” (needs docker installed) or just “jib:build” (dockerless but needs to define credentials for accessing the registry). * The profile “buildpack” has as goal property “spring-boot:build-image” (which also needs docker installed and relies on Paketo buildpack). properties.put("spring-boot.build-image.name", imageName); // Avoid recursion properties.put("skipTests", "true"); InvocationRequest request = new DefaultInvocationRequest() .setPomFile(new File(cwd, "pom.xml")) .setGoals(Arrays.asList("package", System.getProperty("org.kie.samples.goal"))) .setInputStream(new ByteArrayInputStream(new byte[0])) .setProperties(properties);  This will first trigger the package-dependencies-kjar goal of the kie-maven-plugin which also moves the defined kjars and dependencies for creating an immutable spring-boot application. In our tests, these kjars are not static, but installed dynamically from the path "resources" where the business applications are located: private static void installKjar(String path) { File cwd = new File(path); Properties properties = new Properties(); // Avoid recursion properties.put("skipTests", "true"); InvocationRequest request = new DefaultInvocationRequest() .setPomFile(new File(cwd, "pom.xml")) .setGoals(Arrays.asList("clean","install")) .setInputStream(new ByteArrayInputStream(new byte[0])) .setProperties(properties);  With this setup, when the test class instantiates the spring-boot container (system-under-test), the maven lifecycle plugins execute the following actions: * First, creates the kjars for different containers (business applications) with the same artifact but different version * Moves these kjars to ${project.build.directory}/target/classes/KIE-INF/lib * Builds the image with the corresponding builder * Uses that system-under-test to verify that its deployment was successful and exposes the business applications.  IMAGE BUILDING WITH JIB We rely on to create the image and store it in the local docker daemon with the goal jib:dockerBuild. Even though this plugin can be dockerless, in our tests we are using testcontainers, therefore, we need docker in place. For layering, we use the “extraDirectories” option to configure the directories containing kjars  for adding them to the image in the right path (${image.workdir}/classes/KIE-INF/lib/). &lt;extraDirectories&gt; &lt;paths&gt; &lt;path&gt; &lt;from&gt;target/classes/KIE-INF/lib/&lt;/from&gt; &lt;into&gt;${image.workdir}/classes/KIE-INF/lib/&lt;/into&gt; &lt;/path&gt; &lt;/paths&gt; &lt;/extraDirectories&gt;  N.B.: image.workdir will be the root directory on the container where the app’s contents are placed (appRoot property), assigning the value “/workspace/BOOT-INF” to have the same working directory for both tools. Notice that “/workspace” is the default one for Paketo buildpack. For optimizing the image, as we are placing the kjars in that directory, we have to filter them out from the default directory (resources) assigned by jib. We make this with the JibLayerFilterExtension. &lt;pluginExtensions&gt; &lt;pluginExtension &lt;implementation&gt; com.google.cloud.tools.jib.maven.extension.layerfilter.JibLayerFilterExtension &lt;/implementation&gt; &lt;configurationimplementation= "com.google.cloud.tools.jib.maven.extension.layerfilter.Configuration"&gt; &lt;filters&gt; &lt;filter&gt; &lt;glob&gt;${image.workdir}/resources/KIE-INF/lib/*&lt;/glob&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;/configuration&gt; &lt;/pluginExtension&gt; &lt;/pluginExtensions&gt; These are the logs by jib-maven-plugin that summarizes all its actions: [INFO] --- jib-maven-plugin:3.2.1:dockerBuild (default-cli) @ springboot-image-builder-test --- [INFO] Running extension: com.google.cloud.tools.jib.maven.extension.layerfilter.JibLayerFilterExtension [INFO] Running Jib Layer Filter Extension [INFO] [INFO] Containerizing application to Docker daemon as local/kie-server-springboot:1659651590933... [WARNING] Base image 'eclipse-temurin:8-jre' does not use a specific image digest - build may not be reproducible [INFO] Getting manifest for base image eclipse-temurin:8-jre... [INFO] Building dependencies layer... [INFO] Building snapshot dependencies layer... [INFO] Building resources layer... [INFO] Building classes layer... [INFO] Building jvm arg files layer... [INFO] Building extra files layer... [INFO] The base image requires auth. Trying again for eclipse-temurin:8-jre... [INFO] Using base image with digest: sha256:b9d049b16f8fa5ede13b167bcd653cea64d7f6f29f12d44352ce115aa956b0df [INFO] [INFO] Container entrypoint set to [java, -cp, /workspace/BOOT-INF/resources:/workspace/BOOT-INF/classes:/workspace/BOOT-INF/libs/*, org.kie.server.springboot.samples.KieServerApplication] [INFO] Loading to Docker daemon... [INFO] [INFO] Built image to Docker daemon as local/kie-server-springboot:1659651590933 Let’s use the “” tool to analyze the generated image. The last layer is only for the business applications –extra files layer– (just 27 kB in this case). Notice that green files mean that only those are new for that layer: The "classpath layer" is the layer above (again, only 27 kB). Next, there is a layer for the main application classes ("classes layer") that takes 11 kB: Then, we have the “resources layer” with the application.properties (1.9 kB), where we have filtered the business applications out: Finally, the “snapshot dependencies layer” (24 MB), because in our example we are relying on a SNAPSHOT version of kie-server-spring-boot-starter: And the last of jib-maven-plugin layer is for the rest of the dependencies (128 MB): With this interesting analysis, we can check how Jib is layering based on its internal policies and extraDirectories configuration with the pluginExtension for filtering out.  Notice that if instead of SNAPSHOTs, we are in Production we can base our layering on any pattern present in all jars’ names like “Final” or “redhat”. IMAGE BUILDING WITH BUILDPACK Another tool to create Docker-compatible images is . The spring-boot-maven-plugin includes direct integration with buildpacks. In this case, we will use the goal spring-boot:build-image, with the buildpack profile. It produces the same image as the tool. We enable the layering with the property “enabled” set to true, and the configuration depends on the "layers.xml" file that was explained in the previous article. &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${springboot.version}&lt;/version&gt; &lt;configuration&gt; &lt;layers&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;configuration&gt;${project.basedir}/src/layers.xml&lt;/configuration&gt; &lt;/layers&gt; &lt;image&gt; &lt;name&gt;${spring-boot.build-image.name}&lt;/name&gt; &lt;/image&gt; &lt;/configuration&gt; &lt;/plugin&gt;  When executing, it pulls the Paketo builder base image and runs a set of stages (DETECTING, ANALYZING, RESTORING, BUILDING, and EXPORTING to the docker registry). We can tune some properties (out of the scope of this article) to obtain a different image result. For example, modifying the underlying JVM, but basically, there are optimizations under the hood and its execution is pretty straightforward. Once built, a container is instantiated from this image in our tests and we can see how auto-scan is detecting the business application containers: KieServerAutoConfiguration: autoscan in folder /workspace found KieContainerResource [containerId=evaluation-2.0.0, releaseId=org.kie.server.springboot.samples:evaluation:2.0.0, resolvedReleaseId=org.kie.server.springboot.samples:evaluation:2.0.0, status=STARTED] deployment KieServerAutoConfiguration: autoscan in folder /workspace found KieContainerResource [containerId=evaluation-1.0.0, releaseId=org.kie.server.springboot.samples:evaluation:1.0.0, resolvedReleaseId=org.kie.server.springboot.samples:evaluation:1.0.0, status=STARTED] deployment As said before, “workspace” is the default image working directory for Paketo buildpacks, so there is no need to set up this environment variable (org.kie.maven.resolver.folder) as its default value is the same. Again, if we execute dive with the name of this image, we obtain a pretty similar result to Jib for the application layers. CONCLUSION: BUILT WITH JIB EITHER BUILDPACKS, BUT ALWAYS TEST IMAGES We have seen there are some interesting alternatives to Dockerfile for building images. In the case of the KIE server, we can take advantage of layering to create a “business application layer” on top.  These images are like fat-jars, containing all the dependencies (but exploded) and with auto-scan detection for the included business-application containers. If you don’t want the statement that goes “Although tests cannot prove the absence of bugs, every bug proves the absence of tests” to become true, then, you need tests for these images to be more confident in them. With these tools (Jib or buildpacks), we obtain a similar result but you can verify them both in the same project. In this article, we have covered how to test the images after being built as part of the maven lifecycle with the help of testcontainers library. Notice that there’s no official release community or product spring-boot image for KIE server. Recently, KIE server has added support for deploying exploded images () and with this project, we have tested that the mechanism is working fine and it’s valid for different modern Cloud Native image builders like Jib or Buildpacks. Happy jibbing and buildpacking with tests (of course)! The post appeared first on .</content><dc:creator>Gonzalo Muñoz Fernández</dc:creator></entry><entry><title type="html">WildFly 27 Alpha4 is released</title><link rel="alternate" href="https://wildfly.org//news/2022/08/05/WildFly27-Alpha4-Released/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2022/08/05/WildFly27-Alpha4-Released/</id><updated>2022-08-05T00:00:00Z</updated><content type="html">Today we have released the 27.0.0.Alpha4 version of WildFly, now available on the . This release serves as a major milestone on our way toward support for Jakarta EE 10 in WildFly, as it is the first release of standard WildFly that is based on the Jakarta EE APIs that are planned for the upcoming . Until this release, only has offered any kind of support for Jakarta EE beyond EE 8. As discussed in my January , the main focus of the WildFly developers as we work on WildFly 27 is implementing Jakarta EE 10 support. That work has now reached a point where it’s useful for our community to have an early look at our planned EE 10 implementation. We’ve also done a WildFly Preview 27.0.0.Alpha4 release. The differences between standard WildFly and WildFly Preview are currently rather minimal, as the EE 9+ support that’s been WildFly Preview’s biggest calling card has now been brought into standard WildFly. A major difference between WildFly Preview and standard WildFly is Preview retains the feature that will bytecode transform deployments that use the EE 8 javax.* APIs so that they instead use the analogous jakarta.* APIs. We do not intend to include that feature in standard WildFly, but we’re retaining it in WildFly Preview, at least for now. (See 'WildFly Preview Support for EE 8 Deployments' in the for more on this feature.) Note that we have not added a 'Servlet-Only Distribution' variant of WildFly to . The WildFly project is no longer producing that distribution. I encourage users looking for the kind of slimmer server installation formerly provided by the 'Servlet-Only Distribution' to use . We’re also not releasing quickstarts or cloud images for this release. WHAT’S NEW? In a nutshell, what’s new is that standard WildFly provides the EE 10 variant of all the EE specifications it has traditionally offered. EE 8 is no longer provided. The full list of issues resolved in Alpha 4 is available . Note that we’ve produced two other Alphas since I . Those alphas primarily provided additional milestones on the way to providing EE 10 support in WildFly Preview. The issues resolved in Alpha2 are available , while those in Alpha3 are . JAVA SE SUPPORT You can run 27.0.0.Alpha4 on Java SE 11 or Java SE 17. The WildFly project no longer supports Java SE 8 in our feature releases, although our planned 26.1.2 bug fix release will support SE 8. STANDARDS SUPPORT The 27.0.0.Alpha4 release is not a certified compatible implementation of any Jakarta EE specification, nor is it a certified compatible implementation of any MicroProfile specification. This is a milestone release for which we have not yet pursued any certification. UPCOMING RELEASES Over the next couple of weeks the WildFly developers will be finalizing plans for when we will release WildFly 27.0.0.Beta1, 27.0.0.Final, and 26.1.2.Final. Our intent is to release the latter later this month; we just need to work out precisely when. Personally, I think aiming for a WildFly 27.0.0.Final in the September timeframe would be good, with a single feature complete Beta released a couple of weeks before the Final. It’s possible we will do a 27.0.0.Alpha5 before we move on to Beta1; if so I don’t think it will be a major change from Alpha4. ENJOY! Thank you for your continued support of WildFly. We’d love to hear your feedback at the .</content><dc:creator>Brian Stansberry</dc:creator></entry><entry><title type="html">Profiling to improve DMN file&amp;#8217;s loading time: Final Part</title><link rel="alternate" href="https://blog.kie.org/2022/08/profiling-to-improve-dmn-files-loading-time-final-part.html" /><author><name>Daniel José dos Santos</name></author><id>https://blog.kie.org/2022/08/profiling-to-improve-dmn-files-loading-time-final-part.html</id><updated>2022-08-04T21:13:13Z</updated><content type="html">, we saw about what is profiling, profiling GWT and started to analyze a DMN file case which took too much time to load in the editor. In this second and final part of the post, we will explore the snapshot collected by the Profiling Tool and do the proper changes in the DMN Editor to fix the bottlenecks. ANALYZING THE PROFILING SNAPSHOT With everything set, we ran the profiling tool again and take another snapshot. Here is the result we got: As we can see, the "hot path" is expanded and now readable by a human being. Unfortunately, the source map is not supported by Firefox Profiling Tool in this scenario, the tool we used to profile, so we can’t see exactly in our code where those methods are being called but having the real name and call stack it is not hard to understand what is happening and where those methods are. So we can navigate through the call stack expanding the calls. The key here is to follow the path of the left column. The profiling tool takes samples of the running code from time to time and sees what is being run each time it takes that sample. It is like calling your kid every minute for 10 minutes and taking a note about what he is doing. If 9 times he said that he is playing a game and one time he said that he is checking social networks, you can say that 90% of the time he is playing games. That’s what Profiler did here. He is saying that our kid is 90% of the time calling "onRefreshDecisionComponents" that is being called by "fireEvent" which is being called by "callback" and so on: If we go deeper in the stack, we can see exactly what "onRefreshDecisionComponents" means: "loadModelComponents". So, the model components are being loaded every time the event "onRefreshDecisionComponents" are fired. Why that event is being fired so many times? We go up the call stack: There is. "beforeElementUpdate". It means that every time an element is updated, the "onRefreshDecisionComponents" is fired, probably to keep synchronized the Decision Components Navigator and the elements. But why is taking so much time? Do we need to call it at this moment? THE SOLUTION So to understand how "beforeElementUpdated" is being called, I just put a break point here and run the same process again, but now not profiling, just debugging, to find out what was happening there. What I found out was quite obvious and maybe you already got it without the need of debug: "beforeElementUpdate" was being called for each element of our big DMN File. That means that if we have 1000 nodes in the DMN file, in the end, the Decision Components Navigator will be updated 1000 times! Why do we need to update the Decision Components Navigator 1000 and not the only one after every node is loaded? : before loading, the file, just suspend the Decision Components Node update and after the file is fully loaded I call it once. Before this simple change, the file was taking 3:53 minutes to be loaded. Now it is being loaded in 33 seconds just because we update the user interface when the file is fully loaded. We also keep the previous behavior that updates the interface when a single node is changed, so none of the features is lost. If we rerun the profile, we will see that the "onRefreshDecisionComponents" is not even being shown by the Profiler again! CONCLUSION Sometimes improving performance is just a matter of a simple change that is not very obvious and the Profiling Tools can be very helpful in those cases. A few minutes of profiling and changing the code deliveries to our users had a very big performance impact. Less time waiting to load the file is more time to do the real work and to check if your kid is spending too much time in gaming and social media. The post appeared first on .</content><dc:creator>Daniel José dos Santos</dc:creator></entry><entry><title>Display dynamic content from GDB in a custom window</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/04/display-dynamic-content-gdb-custom-window" /><author><name>Andrew Burgess</name></author><id>df4f91c8-d72f-4582-921c-629707f65389</id><updated>2022-08-04T07:00:00Z</updated><published>2022-08-04T07:00:00Z</published><summary type="html">&lt;p&gt;This is the second article in a two-part series about displaying information from the &lt;a href="https://www.sourceware.org/gdb/"&gt;GNU Debugger&lt;/a&gt; (GDB) in a custom window while you are debugging a &lt;a href="/topics/c"&gt;C or C++&lt;/a&gt; program. The &lt;a href="/articles/2022/05/12/add-custom-windows-gdb-programming-tui-python"&gt;first article&lt;/a&gt; introduced GDB's Text User Interface (TUI) and showed how to create a window using the &lt;a href="/topics/python"&gt;Python&lt;/a&gt; API. This second part finishes the example program by displaying values from GDB's history list.&lt;/p&gt; &lt;h2&gt;Loading history values&lt;/h2&gt; &lt;p&gt;To get started, add an extra line in the &lt;code&gt;__init__&lt;/code&gt; method you created in the previous article:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; self._next_history_index = 1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;_next_history_index&lt;/code&gt; variable will be used to fetch values from GDB's history list. The value starts at 1 because the first value in GDB's value history is numbered 1. At each iteration of a loop you'll write, the &lt;code&gt;_next_history_index&lt;/code&gt; variable will represent the next index you need to fetch from GDB's value history.&lt;/p&gt; &lt;p&gt;Next, add two new methods to the &lt;code&gt;history_window&lt;/code&gt; class, which will do the job of fetching values from the history list:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def _add_next_history_value(self): try: value = gdb.history(self._next_history_index) string = value.format_string(pretty_arrays=False, pretty_structs=False) string = "$%d = %s" % (self._next_history_index, re.sub(r"\\s*\n\\s*", " ", string)) self._lines.append(string) self._next_history_index += 1 except: return False return True def _update(self): while self._add_next_history_value(): pass&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;_add_next_history_value&lt;/code&gt; method tries to fetch the next item from GDB's value history. If this is successful, the value is converted to a single-line string and added to the &lt;code&gt;_lines&lt;/code&gt; list. Finally, the method increments the &lt;code&gt;_next_history_index&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To keep this tutorial simple, the method converts each value to be represented to a single line. This conversion uses the &lt;code&gt;re.sub&lt;/code&gt; call, which replaces any newline characters with a single space using a regular expression. To enable the use of a regular expression, you need to add the following line to the top of the &lt;code&gt;history.py&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;import re&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;_update&lt;/code&gt; method just calls &lt;code&gt;_add_next_history_value&lt;/code&gt; until all history values have been processed.&lt;/p&gt; &lt;p&gt;Finally, you need to call &lt;code&gt;_update&lt;/code&gt; in two places.&lt;/p&gt; &lt;p&gt;First, call &lt;code&gt;_update&lt;/code&gt; from the &lt;code&gt;__init__&lt;/code&gt; method to ensure that, as soon as your window is created, all existing history values are loaded into the &lt;code&gt;_lines&lt;/code&gt; list. The complete &lt;code&gt;__init__&lt;/code&gt; method should now look like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def __init__(self, tui_window): self._tui_window = tui_window self._tui_window.title = 'Value History' self._before_prompt_listener = lambda : self._before_prompt() gdb.events.before_prompt.connect(self._before_prompt_listener) self._lines = [] self._next_history_index = 1 self._update()&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, add a call to &lt;code&gt;_update&lt;/code&gt; from the &lt;code&gt;_before_prompt&lt;/code&gt; method, replacing the existing debug line. The full &lt;code&gt;_before_prompt&lt;/code&gt; method should now look like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def _before_prompt(self): self._update() self.render()&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And with these changes, you have a basic, working history window. Restart GDB using the command line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;gdb -ex 'source history.py' \ -ex 'tui new-layout example_1 history 1 cmd 1 status 1' \ -ex 'layout example_1'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Figure 1 shows what the window should look like in action after entering a few commands in the command window:&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="/sites/default/files/values.png" data-featherlight="image"&gt;&lt;img src="/sites/default/files/styles/article_full_width_1440px_w/public/values.png?itok=925ykKEQ" width="490" height="320" alt="The Value History screen displays values in GDB dynamically." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The Value History screen displays values in GDB dynamically. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Value History screen displays values in GDB dynamically.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Preparing for scrolling&lt;/h2&gt; &lt;p&gt;What you have so far is great. But there is one problem. Once the window gets a lot of history values, the earlier ones are lost off the top of the window. It would be great if you could scroll back to view earlier values. So this will be the last feature you add in this tutorial.&lt;/p&gt; &lt;p&gt;But first, you need to rework the code a little to make it easier to add scrolling support.&lt;/p&gt; &lt;p&gt;Add the following methods to your &lt;code&gt;history_window&lt;/code&gt; class:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def _history_count(self): return self._next_history_index - 1 def _display_start(self): return self._max_history_start() def _max_history_start(self): count = self._history_count() height = self._tui_window.height return max(1, count - height + 1)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;_history_count&lt;/code&gt; method returns the number of history items that have been loaded into the &lt;code&gt;_lines&lt;/code&gt; variable.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;_display_start&lt;/code&gt; method returns the index of the first history value that should be displayed in the window. You don't do much here yet, but will extend the method later.&lt;/p&gt; &lt;p&gt;Finally, &lt;code&gt;_max_history_start&lt;/code&gt; returns the history value index that the code should start from (that is, the value displayed at the top of the window) so that the last known history value also appears in the window (at the bottom).&lt;/p&gt; &lt;p&gt;Finally, go back to the following line that is currently in your &lt;code&gt;render&lt;/code&gt; method:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; lines = self._lines[-height:]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Replace that line with the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; start = self._display_start() - 1 end = start + height lines = self._lines[start:end]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The function is now printing &lt;code&gt;height&lt;/code&gt; number of lines starting from &lt;code&gt;_display_start()&lt;/code&gt;. The &lt;code&gt;- 1&lt;/code&gt; is required because &lt;code&gt;_display_start()&lt;/code&gt; returns a history index, which counts from 1, whereas &lt;code&gt;_lines&lt;/code&gt; is a Python list, indexed from 0.&lt;/p&gt; &lt;p&gt;After these changes, the &lt;code&gt;history_window&lt;/code&gt; should work just as it did before, and now you're ready for the final part of this tutorial.&lt;/p&gt; &lt;h2&gt;Scrolling support&lt;/h2&gt; &lt;p&gt;You need to make three more small changes to add scrolling support.&lt;/p&gt; &lt;p&gt;First, add the following line to the &lt;code&gt;__init__&lt;/code&gt; method before the call to &lt;code&gt;self._update()&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; self._vscroll_start = None&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This variable acts as a marker to indicate whether the window is scrolled. When set to &lt;code&gt;None&lt;/code&gt;, the window is not scrolled. Therefore, new values should be added to the end of the window and old values should disappear from the top. In contrast, when the variable is set to an integer, it indicates which history value to scroll back to. The window will then always display items starting from that index.&lt;/p&gt; &lt;p&gt;Next, rewrite the &lt;code&gt;_dispay_start&lt;/code&gt; method like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def _display_start(self): if self._vscroll_start is None: start = self._max_history_start() else: start = self._vscroll_start return start&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now, if &lt;code&gt;_vscroll_start&lt;/code&gt; has been set, the window treats it as the index to start the display. If &lt;code&gt;_vscroll_start&lt;/code&gt; is not set, the method does things exactly as before.&lt;/p&gt; &lt;p&gt;Finally, add the following &lt;code&gt;vcsroll&lt;/code&gt; method to your &lt;code&gt;history_window&lt;/code&gt; class:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def vscroll(self, num): start = self._display_start() start += num start = max(1, start + num) max_start = self._max_history_start() if start &amp;gt;= max_start: self._vscroll_start = None else: self._vscroll_start = start self.render()&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;num&lt;/code&gt; argument indicates the number of lines by which GDB would like to scroll the window contents. Pressing the up or down arrow keys results in a single line change, whereas the PageUp or PageDown keys result in a larger change based on the current size of the window.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;vscroll&lt;/code&gt; method figures out the history index for the current first line of the window, and adjusts this index by the value of &lt;code&gt;num&lt;/code&gt;. The method clamps this value to some sane bounds: thus, you can't scroll back before index 1 (the first GDB history index), nor should you scroll forward beyond the value of &lt;code&gt;max_start&lt;/code&gt;. This variable stores the index from which you can start printing items and still get the last item from the history shown within the window.&lt;/p&gt; &lt;p&gt;Finally, if the user has scrolled as far down as the value in &lt;code&gt;max_start&lt;/code&gt;, the method sets &lt;code&gt;_vscroll_start&lt;/code&gt; to &lt;code&gt;None&lt;/code&gt;. This indicates that as new history values appear, they should be added to the bottom of the window, pushing older values off the top.&lt;/p&gt; &lt;p&gt;And with that, your window is complete. You can scroll back to view all the old history values, and forward again to view the latest history values.&lt;/p&gt; &lt;h2&gt;What next?&lt;/h2&gt; &lt;p&gt;There are two useful TUI window methods you haven't used in this tutorial: &lt;code&gt;hscroll&lt;/code&gt; and &lt;code&gt;click&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;hscroll&lt;/code&gt; method allows horizontal scrolling, just as &lt;code&gt;vscroll&lt;/code&gt; allows vertical scrolling. A good exercise would be to add horizontal scrolling to your history window. Currently, any long history values are truncated. It would be great if you could scroll left and right to view the full value.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;click&lt;/code&gt; method allows basic mouse interaction with the window. You could use this method to enhance the example to display history values in their multiline format and use mouse clicks to expand or hide the full values.&lt;/p&gt; &lt;p&gt;To read more about the &lt;code&gt;hscroll&lt;/code&gt; and &lt;code&gt;click&lt;/code&gt; methods, see the &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/TUI-Windows-In-Python.html#TUI-Windows-In-Python"&gt;TUI-specific documentation&lt;/a&gt;. To read more about GDB's Python API, see the &lt;a href="http://     https://sourceware.org/gdb/onlinedocs/gdb/Python-API.html"&gt;complete Python API documentation&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="/articles/2022/08/04/display-dynamic-content-gdb-custom-window" title="Display dynamic content from GDB in a custom window"&gt;Display dynamic content from GDB in a custom window&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br&gt;&lt;br&gt;</summary><dc:creator>Andrew Burgess</dc:creator><dc:date>2022-08-04T07:00:00Z</dc:date></entry><entry><title type="html">Use the wildfly-maven-plugin to create a Docker image of your application</title><link rel="alternate" href="https://wildfly.org//news/2022/08/04/wildfly-maven-docker/" /><author><name>Jeff Mesnil</name></author><id>https://wildfly.org//news/2022/08/04/wildfly-maven-docker/</id><updated>2022-08-04T00:00:00Z</updated><content type="html">In this article, we will explain how a developer using the Docker image for WildFly can take advantage of the new capabilities of the wildlfy-maven-plugin and the new WildFly runtime image to build their container image. We will describe the changes required to move to this new architecture. Once the changes are done, we will provide some examples of the benefits that can be gained from this new architecture. WILDFLY, DOCKER, S2I AND WHAT ARE THE SYNERGIES? WildFly provides a Docker image at that provides a vanilla WildFly server based on its default standalone configuration. WildFly also provides Source-to-image (S2I) images to be able to create an application image from the application source using tools targeting OpenShift. These two types of images, the "vanilla" Docker image and the OpenShift S2I images, have no connection and no synergy. A lot of work has been done in WildFly around provisioning. The S2I images benefitted from this effort but the Docker image did not… until now. While S2I is a good technology to build application images on OpenShift, we realized that we could achieve a more flexible solution that would benefit other container platforms (Kubernetes, Azure) as well as users running WildFly on premise. We decided to focus on a Maven-centric approach to provision WildFly so that Maven (and the user) would be in control of the complete runtime (including the user deployment as well as the WildFly runtime). This Maven-centric approach can also benefit the users of the vanilla Docker image for WildFly and help them move to a consolidated architecture. WILDFLY DOCKER IMAGE There are different ways to use the image to create an application image (that would contain both WildFly and your deployments) but the simplest one is to add the deployment archive to this base image and let WildFly deploy it when it starts. As an example, we will start from a simple Java application, the quickstart. For the purpose of this exercise, the Java application is a blackbox and we will not look at it. We just want to ensure that we can create an application image that can run it. Let’s clone the repository and build the application: git clone https://github.com/wildfly/quickstart.git cd quickstart/microprofile-config mvn clean package Once the Maven build is finished, the deployment archive has been created in target/microprofile-config.war. At this point, we can use the WildFly Docker image to create the application image with a simple Dockerfile: FROM quay.io/wildfly/wildfly ADD target/microprofile-config.war /opt/jboss/wildfly/standalone/deployments/ Let’s build a wildfly-app image from this Dockerfile and run it locally: docker build -t wildlfy-app . docker run -p 8080:8080 wildfly-app That’s all we needed to run WildFly and the application from docker. We can verify that it is working with: curl http://localhost:8080/microprofile-config/ and it replies MicroProfile Config quickstart deployed successfully. You can find the available operations in the included README file. WILDFLY PROVISIONING ARCHITECTURE Let’s now move to the new architecture for WildFly. Jean-Francois Denise extensively described it in the article and focused on the Source-to-Image (S2I) capabilities of the architecture. In this article, we will see that this architecture also benefits users who are not using S2I and want to keep control of the creation of their application images. With this new architecture, the provisioning of WildFly (which provides the ability to download and create a distribution of WildFly fit for the application requirements) is handled by the Maven plugin org.wildfly.plugins:wildfly-maven-plugin. We can add it to the &lt;build&gt; section of application’s pom.xml to provision WildFly when the package goal is executed by Maven: &lt;plugin&gt; &lt;groupId&gt;org.wildfly.plugins&lt;/groupId&gt; &lt;artifactId&gt;wildfly-maven-plugin&lt;/artifactId&gt; &lt;version&gt;4.0.0.Beta2&lt;/version&gt; &lt;configuration&gt; &lt;feature-packs&gt; &lt;feature-pack&gt; &lt;location&gt;org.wildfly:wildfly-galleon-pack:26.1.1.Final&lt;/location&gt; &lt;/feature-pack&gt; &lt;/feature-packs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;package&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; If we run again mvn clean package, the wildfly-maven-plugin will provision WildFly using its feature pack. Once maven is finished, there will be a target/server directory that contains WildFly and the application deployment. This means that you can directly run WildFly from this directory with the application deployed in it: ./target/server/bin/standalone.sh ... 12:32:00,134 INFO [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0010: Deployed "microprofile-config.war" (runtime-name : "microprofile-config.war") ... 12:32:00,196 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Full 26.1.1.Final (WildFly Core 18.1.1.Final) started in 8929ms - Started 423 of 623 services (341 services are lazy, passive or on-demand) - Server configuration file in use: standalone.xml This is the fundamental change with this architecture: the provisioning, capability trimming and customization of WildFly is now controlled by the application’s pom.xml. In that sense, the application’s pom.xml controls the full runtime of the application. You no longer need to install WildFly, create the deployment and deploy it in WildFly. Instead, the WildFly installation and the deployment is done as part of the Maven build process. You can really see your pom.xml as the central point of your application which is composed of the WildFly runtime and your deployment archive. To leverage this change, we have developed a new image quay.io/wildfly/wildfly-runtime-jdk11 that contains everything needed to run WildFly with OpenJDK 11. If we want to create an application image, we can change the Dockerfile to use this runtime image and add the target/server to it: FROM quay.io/wildfly/wildfly-runtime-jdk11 COPY --chown=jboss:root target/server $JBOSS_HOME RUN chmod -R ug+rwX $JBOSS_HOME Let’s build again the wildfly-app image from this updated Dockerfile and run it: docker build -t wildlfy-app . docker run -p 8080:8080 wildfly-app We can see that there is no change from a caller perspective and the application can still be queried with: curl http://localhost:8080/microprofile-config/ MOVING FROM WILDFLY DOCKER IMAGE TO RUNTIME IMAGE Let’s review what is needed to move from the vanilla Docker image to the new runtime image for WildFly: 1. add the org.wildfly.plugins:wildfly-maven-plugin to the application’s pom.xml 2. update the Dockerfile to use the new runtime image and add the target/server directory Now that we have moved to the new architecture, what are the benefits of it? CAPABILITY TRIMMING WildFly provides capability trimming with so that WildFly is provisioned with only the components (mostly Java archives) that are needed to run your application and nothing more. There are two key benefits with capability trimming: * It reduces the security risk as you are not subject to security attacks if the affected components are not present in application at all. * It reduces the size of the server runtime. In our example, our microprofile-config quickstart requires MicroProfile to run. WildFly provides a convenient microprofile-platform that provisions everything that is needed to run MicroProfile applications. We can trim our runtime to only this layer by updating the wildfly-maven-plugin: &lt;configuration&gt; &lt;feature-packs&gt; &lt;feature-pack&gt; &lt;location&gt;org.wildfly:wildfly-galleon-pack:26.1.1.Final&lt;/location&gt; &lt;/feature-pack&gt; &lt;/feature-packs&gt; &lt;layers&gt; &lt;layer&gt;microprofile-platform&lt;/layer&gt; &lt;/layers&gt; &lt;/configuration&gt; If we package again the application with mvn clean package, we can notice that the size of the target/server went from 250M to 73M and a lot of jars that were not needed to run the application are no longer present. PACKAGING SCRIPTS The wildfly-maven-plugin also provides the ability to execute JBoss CLI commands when WildFly is provisioned. This allows you to substantially modify the standalone configuration to better fit the application requirements. It has no impact on the application image as these scripts are only invoked during provisioning. As a basic example, let’s say we want to support Cross-Origin Resource Sharing (CORS) that requires to add some resources to the undertow subsystem. To active CORS in our application, we need to write a CLI script that creates these resources and put them in the application project in the src/main/scripts/cors.cli: echo Adding Undertow Filters for CORS # Access-Control-Allow-Origin /subsystem=undertow/server=default-server/host=default-host/filter-ref="Access-Control-Allow-Origin":add() /subsystem=undertow/configuration=filter/response-header="Access-Control-Allow-Origin":add(header-name="Access-Control-Allow-Origin",header-value="${env.CORS_ORIGIN:*}") # Access-Control-Allow-Methods /subsystem=undertow/server=default-server/host=default-host/filter-ref="Access-Control-Allow-Methods":add() /subsystem=undertow/configuration=filter/response-header="Access-Control-Allow-Methods":add(header-name="Access-Control-Allow-Methods",header-value="GET, POST, OPTION, PUT, DELETE, PATCH") # Access-Control-Allow-Headers /subsystem=undertow/server=default-server/host=default-host/filter-ref="Access-Control-Allow-Headers":add() /subsystem=undertow/configuration=filter/response-header="Access-Control-Allow-Headers":add(header-name="Access-Control-Allow-Headers",header-value="accept, authorization, content-type, x-requested-with") # Access-Control-Allow-Credentials /subsystem=undertow/server=default-server/host=default-host/filter-ref="Access-Control-Allow-Credentials":add() /subsystem=undertow/configuration=filter/response-header="Access-Control-Allow-Credentials":add(header-name="Access-Control-Allow-Credentials",header-value="true") # Access-Control-Max-Age /subsystem=undertow/server=default-server/host=default-host/filter-ref="Access-Control-Max-Age":add() /subsystem=undertow/configuration=filter/response-header="Access-Control-Max-Age":add(header-name="Access-Control-Max-Age",header-value="1") We can then add this script to the wildfly-maven-plugin by extending its configuration: &lt;plugin&gt; &lt;groupId&gt;org.wildfly.plugins&lt;/groupId&gt; &lt;artifactId&gt;wildfly-maven-plugin&lt;/artifactId&gt; &lt;version&gt;4.0.0.Beta2&lt;/version&gt; &lt;configuration&gt; ... &lt;packaging-scripts&gt; &lt;packaging-script&gt; &lt;scripts&gt; &lt;script&gt;${project.build.scriptSourceDirectory}/cors.cli&lt;/script&gt; &lt;/scripts&gt; &lt;/packaging-script&gt; &lt;/packaging-scripts&gt; ... &lt;/configuration&gt; &lt;/plugin&gt; Once the pom.xml is modified, when you run mvn package, you can notice the CLI commands that are invoked during the packaging of the application: mvn clean package ... [INFO] --- wildfly-maven-plugin:4.0.0.Beta2:package (default) @ microprofile-config --- [INFO] Provisioning server in /Users/jmesnil/Developer/quickstart/microprofile-config/target/server ... [standalone@embedded /] echo Adding Undertow Filters for CORS Adding Undertow Filters for CORS ... With the ability to run CLI scripts when WildFly is provisioned, you are in total control of the configuration of WildFly. FEATURE PACKS WildFly uses feature packs as the building blocks to provision the server. The most important feature pack is WildFly’s own feature pack: org.wildfly:wildfly-galleon-pack:26.1.1.Final to control the installation of WildFly itself. We are also providing additional feature packs to provide additional capabilities to WildFly. It is out of scope of this article to list all of them but let’s discuss two interesting ones: * The provides a set of additional features allowing you to configure a WildFly server to work on the cloud. It adapts WildFly to run on orchestration plaftorms in an optimized way. In particular, it automatically routes server logs to the console, it provisions the health subsystem to monitor the server health with healthiness probes, etc. * The provides JDBC drivers and datasources for various databases. If you include this feature pack, you only need to specify the layer corresponding to the databases you want to use (e.g. postgresql-datasource). You then only need to specify a few environment variables (e.g. DB URL and credentials) at runtime to connect to the database when WildFly is running. CONCLUSION The wildfly-maven-plugin is currently at version 4.0.0.Beta2 with a Final release planned for WildFly 27. It builds on top of the experience we gained from the Bootable Jar and provides a compelling architecture to control the full runtime (WildFly + the application deployments) from the application’s pom.xml. The full customization of WildFly (using feature packs, packaging scripts, etc.) is controlled by the developer so that the runtime fits the user’s application. Creating a container image from this provisioned server is then just a matter of putting it in a runtime image that contains OpenJDK to run the application. We will continue to deliver the vanilla Docker image for WildFly but we are focusing on the new architecture and the new images to expand the capabilities of WildFly. We are looking forward to our users trying this new approach and validates how it improves their workflow. We will also start an open conversation to bring additional synergies between the Docker and S2I images for WildFly that could benefit the whole community. In particular, we want to bring new capabilities such as additional architectures (in particular linux/arm64), newer versions of the JDK (with 17 being the priority), etc. to all our images. If you see any issue or improvements for this new architecture, please open issues on the .</content><dc:creator>Jeff Mesnil</dc:creator></entry><entry><title>Add custom windows to GDB: Programming the TUI in Python</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/03/add-custom-windows-gdb-programming-tui-python" /><author><name>Andrew Burgess</name></author><id>f804e90d-3490-46e4-8d4e-cf8aafedd6c8</id><updated>2022-08-03T07:00:00Z</updated><published>2022-08-03T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://www.sourceware.org/gdb/"&gt;GNU Debugger&lt;/a&gt; (GDB), a popular free and open source tool for &lt;a href="/topics/c"&gt;C and C++&lt;/a&gt; programmers, offers a Text User Interface (TUI) to split the console into multiple windows and display different content in each window. One window will always be a command window, in which you enter the usual GDB commands, but you might also have a source code window, a register contents window, or a disassembly window. Since GDB 11, you can use a &lt;a href="/topics/python"&gt;Python&lt;/a&gt; API to add new window types. This API can be incredibly useful, allowing you to customize GDB to visualize your application's data in new ways.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The Python API for adding TUI windows was actually added to GDB 10. Unfortunately, prior to GDB 11, the &lt;code&gt;gdb.TuiWindow.write&lt;/code&gt; call had some bugs that were not resolved until GDB 11.&lt;/p&gt; &lt;p&gt;In this article, the first in a two-part series, you'll learn how to create a window and load it with dynamic content. The real power of the TUI will be shown in the second article, which shows how to display useful information from GDB.&lt;/p&gt; &lt;h2&gt;Why use the GDB Text User Interface?&lt;/h2&gt; &lt;p&gt;Imagine you are debugging a system containing a cache. You could create a custom window that shows you, at a glance, what is mapped into each cache entry. Or if your system generates an event or activity log, you could set up a window that shows the most recent entries from that log. All of these things could be done in a pure command-line environment, but by creating a custom TUI window, you can view the information on the screen all of the time, making it much easier to spot problems, and so fix bugs more quickly.&lt;/p&gt; &lt;p&gt;For this two-part tutorial, you'll create a new window that just displays GDB's value history. However, once you've finished, you should have the skills needed to adapt this example to display any data you want, including unique views into your application.&lt;/p&gt; &lt;h2&gt;Your first window&lt;/h2&gt; &lt;p&gt;Start by creating the simplest working window possible. Create an empty file named &lt;code&gt;history.py&lt;/code&gt; and then add this content:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;class history_window: def __init__(self, tui_window): self._tui_window = tui_window self._tui_window.title = 'Value History' gdb.register_window_type('history', history_window)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The function &lt;code&gt;gdb.register_window_type&lt;/code&gt; is how you alert GDB to your new window type. The first argument is a string giving the name of the new window (&lt;code&gt;history&lt;/code&gt;, in the example). The second argument is a factory method that GDB will call when it needs to create an instance of the &lt;code&gt;history&lt;/code&gt; window.&lt;/p&gt; &lt;p&gt;The factory method is passed an object of type &lt;code&gt;gdb.TuiWindow&lt;/code&gt;, and should return a brand new object of any type that represents your custom window.&lt;/p&gt; &lt;p&gt;The example uses the &lt;code&gt;history_window&lt;/code&gt; class constructor as the factory method. The &lt;code&gt;tui_window&lt;/code&gt; argument is of type &lt;code&gt;gdb.TuiWindow&lt;/code&gt; and is passed from GDB. The class stores &lt;code&gt;tui_window&lt;/code&gt; into the new instance to be used later on for writing into the window. But for now, all the class does is use the object to set the title of the window to &lt;code&gt;Value History&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Now get GDB to display the new window. Start GDB, and enter this command to load and run your Python script, registering the new window type with GDB:&lt;/p&gt; &lt;pre&gt; &lt;code class="markdown"&gt;(gdb) source history.py&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Use the &lt;code&gt;tui new-layout&lt;/code&gt; command to create a new layout:&lt;/p&gt; &lt;pre&gt; &lt;code class="markdown"&gt;(gdb) tui new-layout example_1 history 1 cmd 1 status 1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;A layout is just a collection of windows that are displayed together. GDB has several built-in layouts, but you just created a new one called &lt;code&gt;example_1&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The remaining arguments to &lt;code&gt;tui new-layout&lt;/code&gt; define the windows you will add to this layout. The number after each window is the relative weight of that window in the layout. The weight is a guide to GDB for how much terminal space to allocate to each window. The weight is only a guide, though. Some windows, such as &lt;code&gt;status&lt;/code&gt;, have a maximum size. Other windows, such as &lt;code&gt;cmd&lt;/code&gt; and &lt;code&gt;history&lt;/code&gt;, can be any size. GDB considers all of these constraints and sizes each window appropriately.&lt;/p&gt; &lt;p&gt;Finally, tell GDB to activate TUI mode and use your new layout:&lt;/p&gt; &lt;pre&gt; &lt;code class="markdown"&gt;(gdb) layout example_1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If everything has worked, your GDB terminal should now look like Figure 1.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="/sites/default/files/blank.png" data-featherlight="image"&gt;&lt;img src="/sites/default/files/styles/article_full_width_1440px_w/public/blank.png?itok=OtE9Mk2t" width="490" height="320" alt="GDB shows a new blank screen with the title Value History." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. GDB shows a new blank screen with the title Value History. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: GDB shows a new blank screen with the title Value History.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;That's not very exciting. Your &lt;code&gt;history_window&lt;/code&gt; window, displayed at the top part of the terminal, shows the &lt;code&gt;Value History&lt;/code&gt; title, but otherwise, the new window remains blank.&lt;/p&gt; &lt;h2&gt;Adding content to the window&lt;/h2&gt; &lt;p&gt;The next task is to generate some content in your window. Every time GDB needs to redraw the window contents, it calls the &lt;code&gt;render&lt;/code&gt; method on the window object. We didn't implement this method initially. If the method doesn't exist, GDB doesn't try to call it, and just leaves the window blank.&lt;/p&gt; &lt;p&gt;So now, add the following &lt;code&gt;render&lt;/code&gt; method to your &lt;code&gt;history_window&lt;/code&gt; class:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def render(self): self._tui_window.erase() self._tui_window.write('Hello World\n') self._tui_window.write('Two\nLines\n') self._tui_window.write('abc'*2000000)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Restart GDB and reload your &lt;code&gt;history.py&lt;/code&gt; script. Rather than retyping the commands into your GDB session, you can pass the commands to GDB from the command line like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;gdb -ex 'source history.py' \ -ex 'tui new-layout example_1 history 1 cmd 1 status 1' \ -ex 'layout example_1'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;GDB should start and immediately switch to TUI mode. The terminal should look like Figure 2.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="/sites/default/files/pre.png" data-featherlight="image"&gt;&lt;img src="/sites/default/files/styles/article_full_width_1440px_w/public/pre.png?itok=xpzfp8uv" width="490" height="320" alt="The Value History screen contains predefined text inserted by your &amp;quot;render&amp;quot; method." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. The Value History screen contains predefined text inserted by your "render" method. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: The Value History screen contains predefined text inserted by your render method.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Note how the very long line of repeated &lt;code&gt;abc&lt;/code&gt; characters wraps at the right side of the window, but is cut off at the bottom of the window. The way GDB fits content into windows is important to keep in mind when you start laying out real content.&lt;/p&gt; &lt;h2&gt;Spotting new history items&lt;/h2&gt; &lt;p&gt;To display every value from GDB's history list, you need some way to spot when new values are added to the history list. GDB doesn't have a Python event that notifies you when values are added to the history list, but there is an event that notifies you when GDB is about to display a new prompt. So you need to catch this event, called &lt;code&gt;before_prompt&lt;/code&gt;, then fetch any new values from the history list and add them to your window content.&lt;/p&gt; &lt;p&gt;Start by adding code to catch the &lt;code&gt;before_prompt&lt;/code&gt; event to your &lt;code&gt;history_window&lt;/code&gt; class. Add the following two lines to the &lt;code&gt;history_window&lt;/code&gt; class, in the &lt;code&gt;__init__&lt;/code&gt; method:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; self._before_prompt_listener = lambda : self._before_prompt() gdb.events.before_prompt.connect(self._before_prompt_listener)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This code creates a new lambda function stored in &lt;code&gt;_before_prompt_listener&lt;/code&gt;. This is the callback function for the event. The next line calls &lt;code&gt;gdb.events.before_prompt.connect&lt;/code&gt; to register this callback with GDB. Now, every time GDB displays a prompt, it will first call this function.&lt;/p&gt; &lt;p&gt;The callback function forwards the call to the &lt;code&gt;_before_prompt&lt;/code&gt; method of your &lt;code&gt;history_window&lt;/code&gt; class. You haven't written that yet, but you will shortly. Before you do, though, let's go back and rework our &lt;code&gt;render&lt;/code&gt; method to make it a little more useful. First, add the following line to the &lt;code&gt;__init__&lt;/code&gt; method:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; self._lines = []&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This list will contain all of the lines for our window.&lt;/p&gt; &lt;p&gt;Now replace the existing &lt;code&gt;render&lt;/code&gt; method with a new one, which displays the content out of your newly created &lt;code&gt;_lines&lt;/code&gt; variable:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def render(self): height = self._tui_window.height width = self._tui_window.width lines = self._lines[-height:] self._tui_window.erase() for l in lines: if len(l) &amp;lt; width: l += "\n" else: l = l[0:width] self._tui_window.write(l)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The first two lines of this method read the &lt;code&gt;height&lt;/code&gt; and &lt;code&gt;width&lt;/code&gt; from the &lt;code&gt;gdb.TuiWindow&lt;/code&gt; object. These values can change every time the &lt;code&gt;render&lt;/code&gt; method is called, because GDB might have resized the window.&lt;/p&gt; &lt;p&gt;The third line of the function uses the &lt;code&gt;height&lt;/code&gt; to select the last few lines from the list of all content lines.&lt;/p&gt; &lt;p&gt;Next, &lt;code&gt;erase&lt;/code&gt; clears the window contents. The function then loops through all the lines to display. If the line is shorter than the screen width, the &lt;code&gt;if&lt;/code&gt; statement adds a newline. Otherwise, the &lt;code&gt;else&lt;/code&gt; statement trims the line to exactly the screen width. Finally, the function calls &lt;code&gt;write&lt;/code&gt; to add the line to the screen.&lt;/p&gt; &lt;p&gt;The last thing you need to do is write the &lt;code&gt;_before_prompt&lt;/code&gt; method:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def _before_prompt(self): self._lines.append('The GDB prompt has been displayed. Good Job!') self.render()&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This method adds content to the &lt;code&gt;_lines&lt;/code&gt; variable, which your &lt;code&gt;render&lt;/code&gt; method can then display.&lt;/p&gt; &lt;p&gt;Restart GDB using this command line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;gdb -ex 'source history.py' \ -ex 'tui new-layout example_1 history 1 cmd 1 status 1' \ -ex 'layout example_1'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With luck, your debugger should look something like Figure 3.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="/sites/default/files/prompt.png" data-featherlight="image"&gt;&lt;img src="/sites/default/files/styles/article_full_width_1440px_w/public/prompt.png?itok=q_XLW2rs" width="490" height="320" alt="The Value History screen displays text you requested before displaying the GDB prompt." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. The Value History screen displays text you requested before displaying the GDB prompt. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: The Value History screen displays text you requested before displaying the GDB prompt.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;If you press the Return key a few times, you should start to see the window fill with text. Next, if you reduce the width of your terminal, you should see the text truncated to the new width (Figure 4).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="/sites/default/files/multi_0.png" data-featherlight="image"&gt;&lt;img src="/sites/default/files/styles/article_full_width_1440px_w/public/multi_0.png?itok=kehMCg9b" width="196" height="320" alt="GDB truncates each line if the window is too narrow to display it." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4. GDB truncates each line if the window is too narrow to display it. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: GDB truncates each line if the window is too narrow to display it.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Excellent. You are almost ready to replace the placeholder strings you've been using with the actual history values into the window, which the second article in this series accomplishes.&lt;/p&gt; &lt;h2&gt;Oh, no—a bug&lt;/h2&gt; &lt;p&gt;Start GDB and load your window, just as before. But this time, switch away from your new layout to a layout that doesn't use your custom window. The full set of GDB commands for this task are:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ gdb (gdb) source history.py (gdb) tui new-layout example_1 history 1 cmd 1 status 1 (gdb) layout example_1 (gdb) layout src&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You should see this error message from GDB in the terminal:&lt;/p&gt; &lt;pre&gt; &lt;code class="markdown"&gt;Python Exception &amp;lt;class 'RuntimeError'&amp;gt;: TUI window is invalid.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The problem is that, once GDB is no longer displaying your history window, the &lt;code&gt;gdb.TuiWindow&lt;/code&gt; that represents it is invalidated and can no longer be used to write to the screen. However, your &lt;code&gt;before_prompt&lt;/code&gt; event handler is still registered and continues to call &lt;code&gt;render&lt;/code&gt;, which will try to write to the screen using the &lt;code&gt;gdb.TuiWindow&lt;/code&gt; object.&lt;/p&gt; &lt;p&gt;To remove this message, you need to disconnect the event listener when your &lt;code&gt;history_window&lt;/code&gt; is being removed from the screen. This task is easily done by adding the &lt;code&gt;close&lt;/code&gt; method to your &lt;code&gt;history_window&lt;/code&gt; class, like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; def close(self): gdb.events.before_prompt.disconnect(self._before_prompt_listener)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now, when switching from the &lt;code&gt;example_1&lt;/code&gt; layout to the &lt;code&gt;src&lt;/code&gt; layout, you no longer get an error.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article got you started with displaying content dynamically in a GDB window. The next article in this series will show you how to display useful information by retrieving the values from GDB's history list.&lt;/p&gt; The post &lt;a href="/articles/2022/08/03/add-custom-windows-gdb-programming-tui-python" title="Add custom windows to GDB: Programming the TUI in Python"&gt;Add custom windows to GDB: Programming the TUI in Python&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br&gt;&lt;br&gt;</summary><dc:creator>Andrew Burgess</dc:creator><dc:date>2022-08-03T07:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.25.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/08/kogito-1-25-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/08/kogito-1-25-0-released.html</id><updated>2022-08-03T04:14:14Z</updated><content type="html">We are glad to announce that the Kogito 1.25.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Improved support of gRCP to Json Mapping. Now Kogito is following * Adding HTTP error codes handling.  * Fixed memory leak when running processes with rules in BusinesRuleTask * Serverless Workflow codestart for Quarkus KNOWN ISSUE(S) * Kogito Builder cannot build from assets with Quarkus Kogito was released with Quarkus 2.11.0.Final artifacts but the Quarkus platform, due to CVE issues, . And, when building from asset files (BPMN, DMN, DRL), the Kogito Builder image  is guessing  directly the Quarkus version from the org.kie.kogito:kogito-build-parent:${KOGITO_VERSION} artifact, which will return the 2.11.0.Final version and thus fail due to missing platform. Workaround is to set the QUARKUS_VERSION `build-env` option with the CLI or directly into the KogitoBuild environment. For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.21.0 artifacts are available at the . A detailed changelog for 1.25.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title type="html">RESTEasy 6.1.0.Final Release</title><link rel="alternate" href="https://resteasy.github.io/2022/08/02/resteasy-6.1.0-release/" /><author><name /></author><id>https://resteasy.github.io/2022/08/02/resteasy-6.1.0-release/</id><updated>2022-08-02T18:11:11Z</updated><dc:creator /></entry><entry><title type="html">Serverless Drools in 3 steps: Kogito, Quarkus, Kubernetes and Knative!</title><link rel="alternate" href="https://blog.kie.org/2022/08/serverless-drools-in-3-steps-kogito-quarkus-kubernetes-and-knative.html" /><author><name>Matteo Mortari</name></author><id>https://blog.kie.org/2022/08/serverless-drools-in-3-steps-kogito-quarkus-kubernetes-and-knative.html</id><updated>2022-08-02T09:38:23Z</updated><content type="html">This short tutorial walks you through the configuration and deployment of a simple serverless application, including autoscaling with scale to zero, thanks to , , OpenShift Serverless with Kubernetes and ! STEP 1: DROOLS APP CREATION WITH CODE.QUARKUS.IO To generate the application as shown in the video, you can use this link: The link will automatically populate for you the basic extensions needed to follow this tutorial. STEP 2: MAINTAIN CONFIGURATION In the application.properties file, you need to maintain a couple of required configuration, following this guideline: quarkus.kubernetes.deployment-target=knative quarkus.container-image.registry=quay.io quarkus.container-image.group=&lt;your own account&gt; You may decide for the Container Image Registry to opt instead for docker.io or similar, and you will need to configure . STEP 3: DEPLOY YOUR DROOLS SERVERLESS APP 🚀 To deploy on Kubernetes, my preference is to deliberately publish a Container Image on a Registry; to follow this strategy, you just need to issue a couple of commands on the terminal. The first command will produce a Container Image for our Drools serverless application, and publish it on the Registry: mvn clean package -Dquarkus.container-image.push=true Then, the second command will effectively deploy that image on the OpenShift cluster: kubectl apply -f target/kubernetes/knative.yml Thanks to Knative, we have autoscaling including autoscale-to-zero, as it’s shown in the video! Autoscale to zero in action, for the Drools serverless app BONUS: SWAGGER UI OPENAPI If you want to use Swagger UI and the OpenAPI web based GUI in your deployed app, simply add quarkus-smallrye-openapi in the , and then maintain the application.properties configuration: quarkus.swagger-ui.always-include=true WANT TO LEARN MORE? We hope you enjoyed this lighthearted tutorial 😄 Did you know that formal training is available from Red Hat? teaches you how to develop, deploy, and auto-scale event driven serverless applications on the Red Hat OpenShift Container Platform. Read the course page to . CONCLUSIONS We have create a simple Drools serverless app with just 3 steps thanks to Kogito and Quarkus; then, thanks to OpenShift Serverless based on Kubernetes and Knative capabilities, we have autoscaling applied, including scale-to-zero. You can use your own Kubernetes cluster while following this tutorial, but don’t forget you can use a free to replicate all the steps exactly as shown in the video! If you enjoyed this simple tutorial, you might be also interested to read this other guide on using the Drools for content based routing on Kafka, using Quarkus and too! Check it out . Questions? Let us know your feedback by leaving a comment below! 👋 The post appeared first on .</content><dc:creator>Matteo Mortari</dc:creator></entry><entry><title>How to configure Helm charts using JKube, part 2</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/01/how-configure-helm-charts-using-jkube-part-2" /><author><name>Rohan Kumar</name></author><id>9fda19e5-56de-420b-b218-04b6ce9119fa</id><updated>2022-08-01T07:00:00Z</updated><published>2022-08-01T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://helm.sh/"&gt;Helm charts&lt;/a&gt; are a popular and convenient way to support different environments on &lt;a href="/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. My previous article, &lt;a href="/articles/2022/04/14/generate-helm-charts-your-java-application-using-jkube-part-1"&gt;How Helm and JKube simplify Kubernetes management, part 1&lt;/a&gt;, explained why generating Helm charts for &lt;a href="/topics/enterprise-java"&gt;Java&lt;/a&gt; applications can be difficult and how it's made easier by &lt;a href="https://www.eclipse.org/jkube"&gt;Eclipse JKube&lt;/a&gt;, which has Maven and Gradle plugins.&lt;/p&gt; &lt;p&gt;In Part 1, you learned how to generate Helm charts for Java automatically without any configuration and to publish them to desired Helm registries. While a zero-configuration approach is a great way to get started, most projects tune the Eclipse JKube plugins to generate the Helm charts to meet their requirements.&lt;/p&gt; &lt;p&gt;This follow-up article explains how to configure Helm charts generated by JKube's Maven and Gradle plugins via various configuration options provided by Eclipse JKube.&lt;/p&gt; &lt;p&gt;Specifically, we will cover:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;XML&lt;/li&gt; &lt;li&gt;Java properties&lt;/li&gt; &lt;li&gt;Resource fragments&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Then we will conclude by demonstrating how to configure your Helm registry where you store your configuration.&lt;/p&gt; &lt;p&gt;Assuming you completed part one, you should already have the JKube Maven plugin (available in &lt;a href="https://github.com/rohankanojia-forks/eclipse-jkube-helm-demo"&gt;this Github repository&lt;/a&gt;) in your sample project:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.eclipse.jkube&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;openshift-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${jkube.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For this series of articles, we use the Maven plugin provided specifically for Red Hat Openshift. You can configure the Helm chart generated by JKube by overriding the opinionated default Helm configuration. The following sections describe how to customize charts via XML, Java properties, and resource fragments.&lt;/p&gt; &lt;h2&gt;Edit XML to configure Helm&lt;/h2&gt; &lt;p&gt;One way to configure a Helm chart managed by JKube is to directly edit the &lt;code&gt;pom.xml&lt;/code&gt; file in the JKube plugin configuration section. Override the default configuration by providing a &lt;code&gt;helm&lt;/code&gt; configuration option in the plugin's &lt;code&gt;configuration&lt;/code&gt; section. Here is an example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.eclipse.jkube&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;openshift-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${jkube.version}&amp;lt;/version&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;helm&amp;gt; &amp;lt;chart&amp;gt;${project.artifactId}&amp;lt;/chart&amp;gt; &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt; &amp;lt;description&amp;gt;JKube Helm Maven demo Helm Chart&amp;lt;/description&amp;gt; &amp;lt;home&amp;gt;https://www.eclipse.org/jkube/&amp;lt;/home&amp;gt; &amp;lt;sources&amp;gt; &amp;lt;source&amp;gt;https://github.com/eclipse/jkube&amp;lt;/source&amp;gt; &amp;lt;/sources&amp;gt; &amp;lt;maintainers&amp;gt; &amp;lt;maintainer&amp;gt; &amp;lt;name&amp;gt;Maintainer1&amp;lt;/name&amp;gt; &amp;lt;email&amp;gt;maintainer1@maintainer1.org&amp;lt;/email&amp;gt; &amp;lt;url&amp;gt;maintainer1.org&amp;lt;/url&amp;gt; &amp;lt;/maintainer&amp;gt; &amp;lt;maintainer&amp;gt; &amp;lt;name&amp;gt;Maintainer2&amp;lt;/name&amp;gt; &amp;lt;email&amp;gt;maintainer2@maintainer2.org&amp;lt;/email&amp;gt; &amp;lt;url&amp;gt;maintainer2.org&amp;lt;/url&amp;gt; &amp;lt;/maintainer&amp;gt; &amp;lt;/maintainers&amp;gt; &amp;lt;icon&amp;gt;https://helm.sh/img/helm.svg&amp;lt;/icon&amp;gt; &amp;lt;keywords&amp;gt;eclipse,jkube,kubernetes,maven&amp;lt;/keywords&amp;gt; &amp;lt;sourceDir&amp;gt;${project.basedir}/target/classes/META-INF/jkube&amp;lt;/sourceDir&amp;gt; &amp;lt;outputDir&amp;gt;${project.basedir}/target/jkube/helm&amp;lt;/outputDir&amp;gt; &amp;lt;chartExtension&amp;gt;tar.gz&amp;lt;/chartExtension&amp;gt; &amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;name&amp;gt;ingress-nginx&amp;lt;/name&amp;gt; &amp;lt;version&amp;gt;3.16.1&amp;lt;/version&amp;gt; &amp;lt;repository&amp;gt;https://kubernetes.github.io/ingress-nginx&amp;lt;/repository&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;/dependencies&amp;gt; &amp;lt;/helm&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/plugin&amp;gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The complete set of supported configuration options is in the &lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin#jkube:helm"&gt;oc:helm documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Now run OpenShift Maven Plugin's resource and the Helm goal to regenerate the YAML manifests and Helm chart. I have added the plugin configuration in a separate xml-configuration profile.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:resource oc:helm -Pxml-configuration&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After running that command, you should be able to see this generated Helm Chart:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: v1 name: jkube-helm-maven home: https://www.eclipse.org/jkube/ sources: - https://github.com/eclipse/jkube version: 1.0.0-SNAPSHOT description: JKube Helm Maven demo Helm Chart keywords: - eclipse - jkube - kubernetes - maven maintainers: - name: Maintainer1 email: maintainer1@maintainer1.org url: maintainer1.org - name: Maintainer2 email: maintainer2@maintainer2.org url: maintainer2.org icon: https://helm.sh/img/helm.svg dependencies: - name: ingress-nginx version: 3.16.1 repository: https://kubernetes.github.io/ingress-nginx &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Configuring Helm using Java properties&lt;/h2&gt; &lt;p&gt;JKube also exposes the Helm configuration via Java properties. Here is an example of how to provide the configuration from the previous section using Maven properties:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &amp;lt;profile&amp;gt; &amp;lt;id&amp;gt;property-configuration&amp;lt;/id&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;jkube.helm.chart&amp;gt;${project.artifactId}&amp;lt;/jkube.helm.chart&amp;gt; &amp;lt;jkube.helm.version&amp;gt;${project.version}&amp;lt;/jkube.helm.version&amp;gt; &amp;lt;jkube.helm.description&amp;gt;JKube Helm Maven demo Helm Chart (Properties)&amp;lt;/jkube.helm.description&amp;gt; &amp;lt;jkube.helm.home&amp;gt;https://www.eclipse.org/jkube/&amp;lt;/jkube.helm.home&amp;gt; &amp;lt;jkube.helm.icon&amp;gt;https://helm.sh/img/helm.svg&amp;lt;/jkube.helm.icon&amp;gt; &amp;lt;jkube.helm.type&amp;gt;openshift&amp;lt;/jkube.helm.type&amp;gt; &amp;lt;jkube.helm.sourceDir&amp;gt;${project.basedir}/target/classes/META-INF/jkube&amp;lt;/jkube.helm.sourceDir&amp;gt; &amp;lt;jkube.helm.outputDir&amp;gt;${project.basedir}/target/jkube/helm&amp;lt;/jkube.helm.outputDir&amp;gt; &amp;lt;jkube.helm.chartExtension&amp;gt;tar.gz&amp;lt;/jkube.helm.chartExtension&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;/profile&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: You can't configure complex elements such as maintainers and sources via properties.&lt;/p&gt; &lt;p&gt;Run the OpenShift Maven Plugin's resource and the Helm goal to regenerate the YAML manifests and Helm chart. As in the previous section, I have added the plugin configuration in a separate property-configuration profile.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:resource oc:helm -Pproperty-configuration&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You should see the generated Helm chart in the &lt;code&gt;target/jkube/helm/openshift/&lt;/code&gt; directory. The chart's contents should be similar to the chart generated with the &lt;code&gt;xml-configuration&lt;/code&gt; profile in the previous step.&lt;/p&gt; &lt;h2&gt;Configuring Helm using resource fragments&lt;/h2&gt; &lt;p&gt;Suppose you want to apply a CustomResource object along with your regular Kubernetes resources during the "resource and apply" phase of the OpenShift Maven Plugin's run. It is impossible to provide a custom resource via an XML configuration or property. Instead, use the third method of generating a Helm chart: &lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin#_resource_fragments"&gt;JKube resource fragments&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;JKube allows users to provide their Kubernetes YAML manifests in a specific directory. The manifests are automatically picked up during oc:resource goal and added to the Helm chart.&lt;/p&gt; &lt;p&gt;For this article, we will use the &lt;a href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#create-custom-objects"&gt;crontab CustomResource&lt;/a&gt; from the Kubernetes documentation. To start, apply the &lt;a href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#create-a-customresourcedefinition"&gt;crontab CustomResourceDefinition&lt;/a&gt; on OpenShift using the command-line tool:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc create -f crontab-crd.yml customresourcedefinition.apiextensions.k8s.io/crontabs.stable.example.com created &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Let's take a look at our crontab custom resource manifest. Usually, you would add this file to the &lt;code&gt;src/main/jkube&lt;/code&gt; directory (the default location of the resource directory). But in our case, we have configured a different resource directory (the &lt;code&gt;fragments&lt;/code&gt; folder in the root directory). The &lt;code&gt;fragments/jkube/crontab-cr.yaml&lt;/code&gt; file contains:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;apiVersion: "stable.example.com/v1" kind: CronTab metadata: name: ${project.artifactId} labels: helm.sh/chart: "${project.artifactId}-${crontab.release}" app.kubernetes.io/managed-by: "${crontab.managedby}" spec: cronSpec: ${crontab.spec} image: ${crontab.image} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note how we provide some of the values in this crontab resource fragment using fields enclosed in &lt;code&gt;${...}&lt;/code&gt;. You must define these values in the Helm parameter configurations, as in the following example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.eclipse.jkube&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;kubernetes-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${jkube.version}&amp;lt;/version&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;resourceDir&amp;gt;${project.basedir}/fragments/jkube&amp;lt;/resourceDir&amp;gt; &amp;lt;helm&amp;gt; &amp;lt;parameters&amp;gt; &amp;lt;parameter&amp;gt; &amp;lt;name&amp;gt;crontab.spec&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;{{ .spec | default "* * * * */5" | quote }}&amp;lt;/value&amp;gt; &amp;lt;/parameter&amp;gt; &amp;lt;parameter&amp;gt; &amp;lt;name&amp;gt;crontab.image&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;{{ .image | default "my-awesome-cron-image" | upper | quote }}&amp;lt;/value&amp;gt; &amp;lt;/parameter&amp;gt; &amp;lt;parameter&amp;gt; &amp;lt;name&amp;gt;crontab.release&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;{{ .Chart.Version }}&amp;lt;/value&amp;gt; &amp;lt;/parameter&amp;gt; &amp;lt;parameter&amp;gt; &amp;lt;name&amp;gt;crontab.managedby&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;jkube&amp;lt;/value&amp;gt; &amp;lt;/parameter&amp;gt; &amp;lt;/parameters&amp;gt; &amp;lt;/helm&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/plugin&amp;gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can specify strings, Maven properties, or Helm template directives as values. Helm parameters can contain non-string fields and periods. JKube automatically resolves Maven properties in a &lt;code&gt;values.yaml&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;Run the OpenShift Maven Plugin's resource and the Helm goal to regenerate the YAML manifests and Helm chart. I have added the plugin configuration in a separate &lt;code&gt;fragment-configuration&lt;/code&gt; profile.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:resource oc:helm -Pfragment-configuration &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This results in the following crontab template:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat target/jkube/helm/jkube-helm-maven/openshift/templates/jkube-helm-maven-cr.yaml --- apiVersion: stable.example.com/v1 kind: CronTab metadata: labels: helm.sh/chart: "jkube-helm-maven-{{ .Chart.Version }}" app.kubernetes.io/managed-by: {{ .Values.crontab.managedby | default "jkube" }} app: jkube-helm-maven provider: jkube version: 1.0.0-SNAPSHOT group: org.eclipse.jkube.demos name: jkube-helm-maven spec: cronSpec: {{ .spec | default "* * * * */5" | quote }} image: {{ .image | default "my-awesome-cron-image" | upper | quote }} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;JKube has replaced &lt;code&gt;${...}&lt;/code&gt; placeholders with values specified in the &lt;code&gt;parameter&lt;/code&gt; configurations. JKube also generated a &lt;code&gt;values.yaml&lt;/code&gt; file for later use by Helm for resolving values. You can inspect the generated &lt;code&gt;values.yaml&lt;/code&gt; file as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat target/jkube/helm/jkube-helm-maven/openshift/values.yaml --- crontab: managedby: jkube &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, install this Helm chart. You should see the crontab custom resource applied to the target cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ helm install --generate-name target/jkube/helm/jkube-helm-maven/openshift/ NAME: openshift-1657293004 LAST DEPLOYED: Fri Jul 8 20:40:05 2022 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Check the applied crontab resource:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc get crontab NAME AGE jkube-helm-maven 86s $ oc get crontab jkube-helm-maven -o yaml apiVersion: stable.example.com/v1 kind: CronTab metadata: annotations: meta.helm.sh/release-name: openshift-1657293004 meta.helm.sh/release-namespace: default labels: app: jkube-helm-maven app.kubernetes.io/managed-by: Helm group: org.eclipse.jkube.demos helm.sh/chart: jkube-helm-maven-1.0.0-SNAPSHOT provider: jkube version: 1.0.0-SNAPSHOT name: jkube-helm-maven namespace: default resourceVersion: "43872" uid: c7b8547e-d0c1-404f-842c-f8e265340b34 spec: cronSpec: '* * * * */5' image: MY-AWESOME-CRON-IMAGE &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Configuring the Helm registry&lt;/h2&gt; &lt;p&gt;Apart from configuring Helm charts, you must configure the registry to which you will push your Helm chart. Like Helm charts, Helm registries can be configured via XML configuration or properties.&lt;/p&gt; &lt;p&gt;I used &lt;a href="https://chartmuseum.com/"&gt;ChartMuseum&lt;/a&gt; for my Helm registry. I have set up a local instance on my machine. You need to change the examples that follow to reflect your Helm registry.&lt;/p&gt; &lt;p&gt;If your project version is a snapshot, use the &lt;code&gt;snapshotRepository&lt;/code&gt; field for Helm registry configuration. Otherwise, use &lt;code&gt;stableRepository&lt;/code&gt;. We will use &lt;code&gt;snapshotRepository&lt;/code&gt; for this demo since it has a 1.0.0-SNAPSHOT Maven version:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.eclipse.jkube&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;kubernetes-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${jkube.version}&amp;lt;/version&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;helm&amp;gt; &amp;lt;snapshotRepository&amp;gt; &amp;lt;name&amp;gt;ChartMuseum&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8080/api/charts&amp;lt;/url&amp;gt; &amp;lt;type&amp;gt;CHARTMUSEUM&amp;lt;/type&amp;gt; &amp;lt;username&amp;gt;user1&amp;lt;/username&amp;gt; &amp;lt;/snapshotRepository&amp;gt; &amp;lt;/helm&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/plugin&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once you have configured your Helm registry details, run the Helm push goal:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:helm-push -Djkube.helm.snapshotRepository.password=secret&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This should upload the Helm chart to the specified registry. You can also provide all this configuration in the form of properties, as shown in the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:helm-push -Djkube.helm.snapshotRepository.name=ChartMuseum \ &amp;gt; -Djkube.helm.snapshotRepository.url=http://localhost:8080/api/charts \ &amp;gt; -Djkube.helm.snapshotRepository.type=CHARTMUSEUM \ &amp;gt; -Djkube.helm.snapshotRepository.username=user1 \ &amp;gt; -Djkube.helm.snapshotRepository.password=secret&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It is also possible to provide registry credentials in Maven settings (&lt;code&gt;~/.m2/settings.xml&lt;/code&gt;) by specifying the Helm registry name and URL:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.eclipse.jkube&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;openshift-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${jkube.version}&amp;lt;/version&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;helm&amp;gt; &amp;lt;snapshotRepository&amp;gt; &amp;lt;name&amp;gt;ChartMuseum&amp;lt;/name&amp;gt; &amp;lt;url&amp;gt;http://localhost:8080/api/charts&amp;lt;/url&amp;gt; &amp;lt;type&amp;gt;CHARTMUSEUM&amp;lt;/type&amp;gt; &amp;lt;/snapshotRepository&amp;gt; &amp;lt;/helm&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/plugin&amp;gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can provide Helm registry credentials in the &lt;code&gt;server&lt;/code&gt; section of &lt;code&gt;settings.xml&lt;/code&gt;. The server ID must match the Helm registry name specified in the plugin configuration. JKube can automatically infer credentials from Maven settings:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&amp;lt;?xml version="1.0" encoding="UTF-8"?&amp;gt; &amp;lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"&amp;gt; &amp;lt;servers&amp;gt; &amp;lt;server&amp;gt; &amp;lt;id&amp;gt;ChartMuseum&amp;lt;/id&amp;gt; &amp;lt;username&amp;gt;user1&amp;lt;/username&amp;gt; &amp;lt;password&amp;gt;secret&amp;lt;/password&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;/servers&amp;gt; &amp;lt;/settings&amp;gt; &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Customized JKube configurations&lt;/h2&gt; &lt;p&gt;So far, you have learned the different methods for generating and publishing Helm charts using Eclipse JKube plugins. We demonstrated how easy it is to customize various aspects of Helm charts and registries utilizing a rich set of configuration options. Please try one or more of these options and provide feedback regarding how we can improve your experience.&lt;/p&gt; &lt;p&gt;For more information, check out the &lt;a href="https://www.eclipse.org/jkube"&gt;Eclipse JKube website&lt;/a&gt;. Feel free to follow us on these channels:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://stackoverflow.com/questions/tagged/jkube"&gt;StackOverflow&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UCpU2tjgpfkTVgeDq-DBSV7A"&gt;YouTube Channel&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://twitter.com/jkubeio"&gt;Twitter&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://gitter.im/eclipse/jkube"&gt;Gitter Chat&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="/articles/2022/08/01/how-configure-helm-charts-using-jkube-part-2" title="How to configure Helm charts using JKube, part 2"&gt;How to configure Helm charts using JKube, part 2&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br&gt;&lt;br&gt;</summary><dc:creator>Rohan Kumar</dc:creator><dc:date>2022-08-01T07:00:00Z</dc:date></entry></feed>
